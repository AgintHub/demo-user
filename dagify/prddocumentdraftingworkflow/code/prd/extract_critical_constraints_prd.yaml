bullets=[PRDBullet(text='Parse the workflow requirements to extract candidate constraint statements using NLP techniques (e.g., keyword matching and context analysis).', reason='Parsing and initial extraction ensure that all explicit and implicit constraint-related phrases are identified as the first step, laying the foundation for effective constraint capture.', impact='HIGH – Correct and comprehensive extraction of constraint candidates is critical, as missing constraints could result in non-compliant or unfeasible requirements.', complexity='MEDIUM – Requires some tuning of NLP methods and potential adaptation for different requirement formats, but leverages well-established libraries.', method="Utilize NLP libraries (spaCy, NLTK, or similar) to identify potential constraint phrases based on keyword spotting (e.g., 'must', 'shall not', 'required to', 'limited by'), syntactic patterns, and sentence context."), PRDBullet(text='Classify extracted constraint statements into categories: technical, business, regulatory, or design.', reason='Categorization adds structure and enables more effective downstream validation, traceability, and risk management.', impact='MEDIUM – Improves readability and organization for users and connected nodes, supports automated merging or reporting.', complexity='LOW – Simple rule-based or ML classification using predefined keywords or training data.', method='Apply a rule-based classifier or a lightweight ML model trained on example constraints to assign each extracted constraint to its most likely category.'), PRDBullet(text='Deduplicate and normalize constraint statements to ensure uniqueness and clarity.', reason='Deduplication and normalization reduce confusion and redundancy, and promote uniformity in presentation for use in formal documents.', impact='MEDIUM – Clean, de-duplicated output prevents overcounting and misrepresentation of constraints, increasing PRD accuracy.', complexity='LOW to MEDIUM – Standard in data processing; may require semantic similarity checks to catch near-duplicates.', method='Use string similarity (Levenshtein distance, paraphrase detection) to merge near-duplicates; standardize terms and phrasing for consistency.'), PRDBullet(text='Reformat all constraints as clearly worded, standalone statements suitable for inclusion in a PRD.', reason='Each constraint must be immediately understandable and actionable by technical and business stakeholders without further interpretation.', impact='HIGH – Directly affects document quality, ensuring constraints are actionable and align with best practices.', complexity='LOW to MEDIUM – Mostly text rephrasing, with some contextual rewriting required.', method="Template-based language generation, post-processing NLP rewriting to enforce a declarative format, e.g., 'The system must ...', 'The product will not ...'."), PRDBullet(text='Validate extracted and normalized constraints against the original workflow requirements to check for omissions or misclassifications.', reason='Backchecking ensures completeness and correctness, lowering the risk of missing or misunderstood requirements.', impact='HIGH – Catching errors early reduces downstream mistakes and costly revisions in later PRD steps.', complexity='MEDIUM – May require manual spot-checking or automated requirement-to-constraint mapping.', method='Implement rule-based cross-checks and, where feasible, user interaction or review loops for flagged uncertainties.'), PRDBullet(text='Output the final list of bullet-pointed constraints as a List[str] for consumption by downstream PRD compilation nodes.', reason='Structured output in an easily consumable format facilitates seamless integration with the next stages of the PRD drafting workflow.', impact='HIGH – Ensures compatibility and modularity across the DAG, supporting automation and traceability.', complexity='LOW – Standardized serialization step.', method='Produce a Python list of strings, formatted for direct inclusion in JSON or markdown as per the output specification.')]
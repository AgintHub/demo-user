bullets=[PRDBullet(text="Extract metric names, objective mappings, and quantifiability indicators from the output of the 'define_success_metrics' node.", reason='This ensures direct alignment between the success metrics defined at the requirements level and those communicated in the PRD, preventing loss or misinterpretation of requirement intent.', impact='HIGH – Accurate extraction preserves traceability and guarantees the PRD metrics are measurable and relevant.', complexity='LOW – Simple data extraction and field mapping.', method="Parse the 'define_success_metrics' output fields (metric_names, metric_objective_mappings, and metric_quantifiability) and store them for formatting."), PRDBullet(text="Format the section heading as a standardized string, e.g., 'Success Metrics'.", reason='Provides consistency for PRD consumers and enables reliable automated assembly into standardized documents.', impact='LOW – Primarily affects presentation and readability.', complexity='LOW – Hardcoded string assignment.', method="Set a static string ('Success Metrics' or similar) for the section_title output field."), PRDBullet(text="For each defined metric, construct a formal, numbered or bulleted string that includes: the metric name or description, the associated mapped objectives (in brief), and an indication of quantifiability (e.g., 'Measured by X', 'Objectively verifiable').", reason='Detailed, structured presentation of each metric ensures clarity, auditability, and easy verification of product success post-implementation.', impact='HIGH – Directly shapes how stakeholders and QA teams interpret success.', complexity='MEDIUM – Requires multi-field synthesis and careful templating.', method="Iterate over metrics; template each as, e.g., '- [Metric Name]: [Description]. Objective(s): [objective mapping]. Quantifiable: [Yes/No] with details.'"), PRDBullet(text="Provide clear, verifiable criteria in each metric’s phrasing using action words such as 'Achieve', 'Increase', 'Reduce', along with a target value or objective measure where available.", reason='Enables future teams and reviewers to objectively determine if a metric has been met, fulfilling the PRD’s foundational purpose.', impact='HIGH – Ensures that success/failure can actually be assessed post-launch.', complexity='MEDIUM – Requires domain awareness and careful rewording in templating.', method='In the formatting logic, check for quantifiability. If true, include target values or measurable endpoints from the source or default template.'), PRDBullet(text='Maintain the order of metrics as defined in the parent node to preserve logical mapping to objectives.', reason='Order can be significant—stakeholders often expect the most critical metrics to appear first, matching objective priority.', impact='MEDIUM – Improves usability for all readers, especially reviewers and product leads.', complexity='LOW – List order preservation during data transformation.', method='Process metrics in list order without sorting; apply stable enumeration in output.'), PRDBullet(text='Output the section heading and the formatted list of metrics as separate fields matching the node’s output structure.', reason='Structured output enables downstream nodes (such as assembly into the final PRD) to easily insert and manipulate the section as needed.', impact='HIGH – Directly affects the integration and reusability of PRD components.', complexity='LOW – Controlled output field naming and assignment.', method="Return a dict/object with 'success_metrics_section_title' and 'success_metrics_list' keys, mapping to section heading and fully formatted list respectively.")]